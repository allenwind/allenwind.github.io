<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="你好，世界！"><title>机器学习之分类问题的评估指标总结 | Erwin Feng Blog</title><link rel="stylesheet" type="text/css" href="/blog/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/blog/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/blog/favicon.ico"><link rel="apple-touch-icon" href="/blog/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/blog/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习之分类问题的评估指标总结</h1><a id="logo" href="/blog/.">Erwin Feng Blog</a><p class="description">内容也是一种社交方式！</p></div><div id="nav-menu"><a class="current" href="/blog/."><i class="fa fa-home"> 首页</i></a><a href="/blog/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/blog/about/"><i class="fa fa-user"> 关于</i></a><a href="/blog/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习之分类问题的评估指标总结</h1><div class="post-meta">2021-10-09<span> | </span><span class="category"><a href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">机器学习深度学习</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E4%B9%8B%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="toc-number">1.</span> <span class="toc-text">二分类之混淆矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E7%A1%AE%E7%8E%87"><span class="toc-number">2.</span> <span class="toc-text">准确率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#P-R%E6%9B%B2%E7%BA%BF%E5%92%8CAP%E9%9D%A2%E7%A7%AF"><span class="toc-number">3.</span> <span class="toc-text">P-R曲线和AP面积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#F-1-score"><span class="toc-number">4.</span> <span class="toc-text">F-1 score</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ROC%E6%9B%B2%E7%BA%BF%E4%B8%8EAUC%E9%9D%A2%E7%A7%AF"><span class="toc-number">5.</span> <span class="toc-text">ROC曲线与AUC面积</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ROC%E6%9B%B2%E7%BA%BF"><span class="toc-number">5.1.</span> <span class="toc-text">ROC曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%98%E5%88%B6"><span class="toc-number">5.2.</span> <span class="toc-text">绘制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AUC"><span class="toc-number">5.3.</span> <span class="toc-text">AUC</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB"><span class="toc-number">6.</span> <span class="toc-text">多分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%88%E5%80%BC%E9%80%89%E6%8B%A9"><span class="toc-number">7.</span> <span class="toc-text">阈值选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%92%8C%E6%80%BB%E7%BB%93"><span class="toc-number">8.</span> <span class="toc-text">应用和总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">9.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="post-content"><p>没有测量就没有科学，同样，机器学习任务也离不开评估指标。评估指标一般来源于对业务的抽象，本文总结分类问题中常用的评估指标。</p>
<span id="more"></span>
<p>在机器学习、深度学习中，有不同的任务，大致可以分为分类、 排序、 回归、序列标注（如分词、NER）、序列预测（如时间序列预测）等几大类任务。这类任务有不同的评估方法，选择与问题相匹配的评估方法有助于快速迭代模型。本文将总结分类任务有关的评估指标，包括二分类、多分类。</p>
<p>这篇文章其实是两年前的学习笔记的总结，不过那时写得比较分散，于是这里整理一下分享出来，也方便自己回顾。</p>
<p>此外，根据业务抽象出更契合场景的评估指标，这个只能具体情况具体说了。</p>
<h2 id="二分类之混淆矩阵"><a href="#二分类之混淆矩阵" class="headerlink" title="二分类之混淆矩阵"></a>二分类之混淆矩阵</h2><p>二分类的重点是分类器输出的阈值的选择，高于阈值的判别为正类，否则为负类。模型预测的正类与负类与和真正的标签比较获得如下<strong>混淆矩阵</strong>，</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">预测类别/真实类别</th>
<th style="text-align:center">正类 P</th>
<th style="text-align:center">负类 N</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">正类</td>
<td style="text-align:center">TP（真阳性）</td>
<td style="text-align:center">FP（假阳性）</td>
</tr>
<tr>
<td style="text-align:center">负类</td>
<td style="text-align:center">FN（假阴性）</td>
<td style="text-align:center">TN（真阴性）</td>
</tr>
<tr>
<td style="text-align:center">总和</td>
<td style="text-align:center">P = TP + FN</td>
<td style="text-align:center">N = FP + TN</td>
</tr>
</tbody>
</table>
</div>
<p>所有标记的样本在预测器下都会分为如下四种预测状态之一：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>计数指标</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>TP (true positives)</td>
<td>正类预测为正类的数量</td>
</tr>
<tr>
<td>FN (false negatives)</td>
<td>正类预测为负类的数量</td>
</tr>
<tr>
<td>FP (false positives)</td>
<td>负类预测为正类的数量</td>
</tr>
<tr>
<td>TN (true negatives)</td>
<td>负类预测为负类的数量</td>
</tr>
</tbody>
</table>
</div>
<p> 显然，以上计数指标的总和即为样本总数，TP+FN+FP+TN为样本总量。大部分模型的输出都是一个$[0, 1]$的值，需要设置一个阈值来判断类别判别为正类或负类，一般情况下这个阈值为$0.5$，当模型输出大于该阈值，则判别为正类，否则为负类。当阈值调得越小，假阳性就越多；多阈值调得越大，假阴性就越多。</p>
<p>所有的正类，</p>
<script type="math/tex; mode=display">
P = TP + FN</script><p>所有的负类，</p>
<script type="math/tex; mode=display">
N = FP + TN</script><h2 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h2><p>准确率之所有样本中，预测正确的比例，即</p>
<script type="math/tex; mode=display">
\begin{align}
\text{accuracy} 
&= \frac{TP+TN}{P+N} \newline
&= \frac{TP+TN}{FP+FN+FP+TN}
\end{align}</script><p>对正负样本不平衡敏感，通过 balanced accuracy 解决这个问题。</p>
<p>与之相反的是<strong>错误率</strong>，</p>
<script type="math/tex; mode=display">
\text{error} = 1 - \text{accuracy}</script><p>有时候我们需要关心模型预测的更多细节，例如一个大型的数据中心，里面有大量的磁盘，那么模型能够识别里面的故障盘的比例是多少（即召回率），或者模型多的多次故障预测，磁盘真的故障的比例多少（精确率）。另外，在一些极端情况下，如数据中心有一百块磁盘，故障盘只有一块，健康盘99块，那么模型直接把所有盘判断为健康，那么模型的预测的准确率也为99%。显然，这样的准确率是没有意义的。</p>
<h2 id="P-R曲线和AP面积"><a href="#P-R曲线和AP面积" class="headerlink" title="P-R曲线和AP面积"></a>P-R曲线和AP面积</h2><p>precision，查准率，预测为正类的样本中，有多少是真的正类，</p>
<script type="math/tex; mode=display">
\text{precision} = \frac{TP}{TP+ \color{red}{FP}}</script><p>recall，查全率，召回率，所有的正类中，有多少被预测为正类</p>
<script type="math/tex; mode=display">
\text{recall} = \frac{TP}{TP+ \color{red}{FN}}</script><p>理想情况下 precision 和 recall 越高越好，但是这两个指标是在一定程度上对立的。precision和recall的计算差异就在FP和FN上。当FP越大，precision就越小，即假阳性越大，把没有问题的样本判别为有问题的样本，这就导致<strong>较低的效率或者说较高的成本</strong>。当FN越大，recall就越小，即假阴性越大，把有问题的样本判别为没有问题的样本，这就导致漏判，<strong>带来较高的风险</strong>。</p>
<p>因此，precision可以看做是一个任务的成本指标，越小成本约大；recall可以看做是一个任务的风险指标，越小风险越大。因此，衡量一个任务的成本与风险可以同时使用precision与recall指标。</p>
<p>对于NER、中文分词等场景，输出往往是集合类型或列表类型，那么precision的计算为，</p>
<script type="math/tex; mode=display">
P(A, B) = \frac{\left| A \cap B \right|}{\left|B\right|}</script><p>recall的计算为，</p>
<script type="math/tex; mode=display">
R(A, B) = \frac{\left| A \cap B \right|}{\left|A\right|}</script><p>A表示<strong>正确的实体</strong>及其所在文本中的位置（NER通常是<code>(entity,label,start,end）</code>这样的形式，而分词是<code>(word, start, end)</code>）集合，B表示<strong>预测的实体</strong>及其所在文本中的集合，即</p>
<script type="math/tex; mode=display">
A = TP \cup FN  \\
B = TP \cap FP</script><p>需要强调，计算评估指标不能直接使用实体的集合，比如考虑一个句子里有两个相同的实体（同名同标签）但是位置不同，模型无论是只识别其中之一还是都识别出来，求集合后的结果都一样，这样是不准确的，无法更准确评估模型。</p>
<p>以precision为纵坐标，recall为横坐标，那么就构成P-R曲线，它越靠近右上角模型性能越好。</p>
<p>P-R 曲线与坐标轴围成的面积叫 AP 分数（Average Precision Score），计算方法为，</p>
<script type="math/tex; mode=display">
\text{AP} = \sum_n (R_n - R_{n-1}) P_n</script><p>类似的是ROC曲线，其与坐标轴围成的面积称为AUC，一会谈到。</p>
<h2 id="F-1-score"><a href="#F-1-score" class="headerlink" title="F-1 score"></a>F-1 score</h2><p>precision 和 recall 的调和平均</p>
<script type="math/tex; mode=display">
F_1 = \frac{2 \cdot \text{precison} \cdot \text{recall}}{\text{precision} + \text{recall}}</script><p>用以反映precision 和 recall的整体性能。通过化简，可以使用混淆矩阵中的四个值表示，</p>
<script type="math/tex; mode=display">
F_{1} = \frac{2TP}{2TP + FP + FN}</script><p>在 precision 和 recall 的重要性不一致的情况下，可以加权，</p>
<script type="math/tex; mode=display">
F_{\beta} = \frac{\text{precision} \cdot \text{recall}}{\frac{\beta^2}{1+\beta^2}\cdot \text{precision} + \frac{1}{1+\beta^2}\cdot \text{recall}}</script><p>可以令</p>
<script type="math/tex; mode=display">
\alpha =\frac {1}{1+\beta ^{2}}</script><p>来化简上式。那么如何理解这个参数$\beta$呢？考虑从极端的边界来看，</p>
<script type="math/tex; mode=display">
\lim_{\beta \to +\infty} F_{\beta} = \text{recall} \\
\lim_{\beta \to 0} F_{\beta} = \text{precision} \\
F_{\beta} \big|_{\beta=1} = F_1</script><p>这意味着：</p>
<ul>
<li>当$\beta=1$时，recall和precision同等重要</li>
<li>当$\beta \lt 1$时，precision更重要</li>
<li>当$\beta \gt 1$时，recall更重要</li>
</ul>
<p>对于NER或中文分词任务，$F_\beta$计算方式为，</p>
<script type="math/tex; mode=display">
F_\beta(A, B) = \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}</script><h2 id="ROC曲线与AUC面积"><a href="#ROC曲线与AUC面积" class="headerlink" title="ROC曲线与AUC面积"></a>ROC曲线与AUC面积</h2><p>ROC曲线全称为<strong>接收者操作特征</strong>曲线（receiver operating characteristic curve），其纵坐标是真阳性率，横坐标是假阳性率。</p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>真阳性率，在所有阳性样本中，模型检测出来的阳性比例，也就是召回率，</p>
<script type="math/tex; mode=display">
\text{tpr} = \frac{TP}{P} = \frac{TP}{TP+FN} = \text{recall}</script><p>假阳性率，把阴性误报成阳性的比例，</p>
<script type="math/tex; mode=display">
\text{fpr} = \frac{FP}{N} = \frac{FP}{FP+TN}</script><p>TPR与FPR对正负样本不平衡不敏感，因为调整阈值下，分母N与P不会变。很多<a href="../10660/">failure prediction papers</a>都使用FAR（false alarm ratio，其实就是fpr）、FDR（failure detection rates的缩写，实质是recall），因此TPR和FPR在具体的情景中也有不同的别称。</p>
<p>以纵坐标是真阳性率，横坐标是假阳性率，得到ROC曲线，</p>
<p><img src="../images/roc-auc-demo-1.png" alt=""></p>
<p>ROC曲线越接近左上角，模型整体性能越好，如图中蓝色曲线比橙色曲线好。黑心虚线就是随机预测的结果。最优结果是fpr恒为0，而tpr恒为1。</p>
<p>绘制 ROC 曲线，最直观的方法是使用一个变动的阈值$\alpha \in [0, 1]$，分别计算该阈值下的tpr与fpr，然后绘制曲线。但是这种方法计算效率并不高。</p>
<h3 id="绘制"><a href="#绘制" class="headerlink" title="绘制"></a>绘制</h3><p>根据ROC曲线的定义，容易绘制ROC曲线。根据标签数据集，容易获得正样本数量$P$，负类样本数量$N$。假设训练好模型，对所有样本的预测概率值进行排序，得到$s_1, s_2, \dots, s_N$。依次使用$t=s_i, i=1, 2, \dots, N$作为阈值，对于预测概率$s_i$大于阈值$t$的样本为$TP$，否则为$FP$，于是就能计算ROC曲线采样点的横坐标与纵坐标：</p>
<ul>
<li>$\frac{TP}{P}$</li>
<li>$\frac{FP}{N}$</li>
</ul>
<p>依次使用$t=s_i, i=1, 2, \dots, N$作为阈值，则能采样到$N$个样本点，进而可以绘制ROC曲线。</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>AUC（Area Under the Curve） 是 ROC 曲线与坐标轴围成的面积，面积越大，模型性能越好。计算方法可以使用梯形法（trapezoidal rule ），即曲线上所有相邻两点的连线与其下方所围成的梯形面积的总和。直观上来看，这种方法获得的计算结果倾向于低估实际的AUC面积。</p>
<p>AUC 的统计意义：</p>
<ul>
<li>AUC值越大的分类器，正确率越高，模型的性能越好，可以作为模型间比较的性能指标</li>
<li>若随机抽取一个阳性样本和一个阴性样本，分类器正确判断阳性样本的值高于阴性样本之几率。比如AUC=0.9，那么有90%的概率，模型对正样本的打分高于对负样本的打分。</li>
</ul>
<h2 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h2><p>二分类指标可以推广到多分类问题上，只不过需要区分两类指标：</p>
<ul>
<li>macro，在所有类别的指标上平均</li>
<li>micro，在整体结果上计算</li>
</ul>
<h2 id="阈值选择"><a href="#阈值选择" class="headerlink" title="阈值选择"></a>阈值选择</h2><p>因此，准确率（Accuracy），精确率（Precision），召回率（Recall） 、$F_{\beta}$这些指标全部依赖模型的阈值选择。因此可以绘制曲线图，刻画随阈值变化以上指标的变化，最优阈值是上述指定指标取最大值时所对应的阈值。例如阈值$\alpha \in [0, 1]$，随其变动的指标$F_1$，那么当$F_1$取最大时，那么对应的$\alpha$取值为0.6，那么该值可以作为模型类别判别的阈值。</p>
<h2 id="应用和总结"><a href="#应用和总结" class="headerlink" title="应用和总结"></a>应用和总结</h2><p>分类性能指标及其别名有如下表格：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>指标</th>
<th>含义</th>
<th>补充</th>
<th>使用情景</th>
</tr>
</thead>
<tbody>
<tr>
<td>错误率 error rate</td>
<td>分类错误数占样本总数</td>
<td>(FN+FP) / (TP+FN+FP+TN)</td>
<td>/</td>
</tr>
<tr>
<td>准确率accuracy</td>
<td>1 - 错误率</td>
<td>(TP+TN) / (TP+FN+FP+TN)</td>
<td>准确率与错误率不足以全面衡量模型。因为在某些情况下，模型把所有样本判别为负类也能获得一个很好的准确率</td>
</tr>
<tr>
<td>精确率 (precision)</td>
<td>precision = TP / (TP+FP)</td>
<td>查准率。本文中的含义：所有故障预测中，有多少比例是真的故障。</td>
<td>当FP很大，即假阳性太多，precision就会很小，这会导致较大的<strong>成本</strong>（较低的效率），因为没有问题的样本被误判为有问题。</td>
</tr>
<tr>
<td>回召率 (recall)</td>
<td>recall = TP / (TP+FN)</td>
<td>查全率。本文中的含义：在所有故障磁盘中，有多少比例被预测出来。</td>
<td>当FN很大，即假阴性太多，recall就会很小，这会导致较大的风险。因为太多有问题的样本没有被检测出来。</td>
</tr>
<tr>
<td>f-score</td>
<td>precision和recall的调和平均</td>
<td>某些场景下，precision 和 recall 的代价是不等的，为了表达这种情况，precision 和recall 可以加权求和。</td>
<td>通常使用F1，用来同时控制precision和recall，前者是<strong>成本</strong>的来源，后者是<strong>风险</strong>的来源。说白了，当precision和recall都重要的情况下，使用该指标。</td>
</tr>
<tr>
<td>FPR或FAR</td>
<td><strong>FAR = FP / (FP + TN)</strong></td>
<td>false alarm ratio，false positive ratio，假阳性率。在本文中的含义：所有正常磁盘中，有多少比例的磁盘被判别为故障。显然这个值越小越好。</td>
<td>TPR曲线实际上就是正样本的累积分布曲线，FPR曲线实际上就是负样本的累积分布曲线</td>
</tr>
<tr>
<td>TPR或FDR</td>
<td>等价于 <strong>recall = TP / (TP+FN)</strong></td>
<td>在机器学习中并没有FDR的定义，它实际为failure detection rates的缩写，等价于recall定义。显然，这个值越大越好。 实际上，FDR与FAR是互相约束，通过ROC曲线可以直观到阈值大小。</td>
<td>根据FAR、FDR的定义，显然，我们需要模型的FAR值越小越好，FDR值越大越好。比较不同模型的预测性能可以直接使用以上指标。</td>
</tr>
<tr>
<td>PR曲线</td>
<td>precision和recall在变动阈值下构成的曲线</td>
<td></td>
<td>正负样本不平衡敏感，因此在正负样本不平衡时使用</td>
</tr>
<tr>
<td>ROC曲线</td>
<td>TPR与FPR在变动阈值下构成的曲线</td>
<td></td>
<td>正负样本不平衡不敏感，因此在正负样本平衡时使用</td>
</tr>
<tr>
<td><strong>AUC</strong></td>
<td>ROC 曲线与坐标轴围起来的面积，用于度量分类任务的整体性能。</td>
<td>AUC 是 ROC 曲线与坐标轴围成的图像的面积</td>
<td>当两条ROC曲线有相交情况时，不好判断模型的优良，可以使用AUC来判断。通常我们使用它来比较两个两个不同模型的整体性能</td>
</tr>
</tbody>
</table>
</div>
<p>在应用上，一般是根据业务情景的需求抽象出评估指标，某些情况下可能还需要根据场景的理解设计更复杂的指标，如给定precision下的recall，这个指标可以理解成在给定的<strong>成本</strong>下，把系统或平台的<strong>风险</strong>尽可能减少。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] 《机器学习》</p>
<p>[2] 维基百科</p>
<p>转载请包括本文地址：<a href="../16051/">https://allenwind.github.io/blog/16051/</a><br>更多文章请参考：<a href="../archives/">https://allenwind.github.io/blog/archives/</a></p>
</div><div class="tags"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E5%88%86%E7%B1%BB/" rel="tag">分类</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E6%8C%87%E6%A0%87/" rel="tag">指标</a></li></ul></div><div class="post-nav"><a class="pre" href="/blog/16113/">Tensorflow的多卡训练：原理和实践</a><a class="next" href="/blog/16003/">天马行空：设计自己的激活函数</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://allenwind.github.io/blog"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="关于"><img class="nofancybox" src="/blog/icon.png"/></a><p>Erwin Feng, 你的认知合作伙伴！</p><a class="info-icon" href="https://twitter.com/username" title="Twitter" target="_blank" style="margin-inline:5px"> <i class="fa fa-twitter-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:admin@domain.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/allenwind" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/blog/categories/C-C/">C/C++</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Go/">Go</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Java/">Java</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E6%95%B0%E5%AD%A6/">数学</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/">数据结构和算法</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">机器学习深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/blog/categories/%E8%AE%B0%E5%BD%95/">记录</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/blog/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/blog/tags/C/" style="font-size: 15px;">C</a> <a href="/blog/tags/Python/" style="font-size: 15px;">Python</a> <a href="/blog/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" style="font-size: 15px;">设计模式</a> <a href="/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 15px;">数据库</a> <a href="/blog/tags/MySQL/" style="font-size: 15px;">MySQL</a> <a href="/blog/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/" style="font-size: 15px;">区块链</a> <a href="/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 15px;">分布式</a> <a href="/blog/tags/SQL/" style="font-size: 15px;">SQL</a> <a href="/blog/tags/NoSQL/" style="font-size: 15px;">NoSQL</a> <a href="/blog/tags/ACID/" style="font-size: 15px;">ACID</a> <a href="/blog/tags/sudo/" style="font-size: 15px;">sudo</a> <a href="/blog/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/blog/tags/C%E8%AF%AD%E8%A8%80/" style="font-size: 15px;">C语言</a> <a href="/blog/tags/Git/" style="font-size: 15px;">Git</a> <a href="/blog/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/blog/tags/git/" style="font-size: 15px;">git</a> <a href="/blog/tags/gcc/" style="font-size: 15px;">gcc</a> <a href="/blog/tags/Systemd/" style="font-size: 15px;">Systemd</a> <a href="/blog/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/" style="font-size: 15px;">命令行</a> <a href="/blog/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/blog/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 15px;">正则表达式</a> <a href="/blog/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 15px;">操作系统</a> <a href="/blog/tags/%E8%AE%B0%E5%BD%95/" style="font-size: 15px;">记录</a> <a href="/blog/tags/go/" style="font-size: 15px;">go</a> <a href="/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/blog/tags/Go/" style="font-size: 15px;">Go</a> <a href="/blog/tags/LRU/" style="font-size: 15px;">LRU</a> <a href="/blog/tags/ARC/" style="font-size: 15px;">ARC</a> <a href="/blog/tags/Java/" style="font-size: 15px;">Java</a> <a href="/blog/tags/%E5%89%91%E6%8C%87Offer/" style="font-size: 15px;">剑指Offer</a> <a href="/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/" style="font-size: 15px;">搜索引擎</a> <a href="/blog/tags/%E5%87%BD%E6%95%B0%E5%BC%8F/" style="font-size: 15px;">函数式</a> <a href="/blog/tags/%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">网络</a> <a href="/blog/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">并发编程</a> <a href="/blog/tags/Stack/" style="font-size: 15px;">Stack</a> <a href="/blog/tags/HTTP/" style="font-size: 15px;">HTTP</a> <a href="/blog/tags/%E5%B9%B6%E5%8F%91/" style="font-size: 15px;">并发</a> <a href="/blog/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" style="font-size: 15px;">网络编程</a> <a href="/blog/tags/%E5%BA%A6%E9%87%8F/" style="font-size: 15px;">度量</a> <a href="/blog/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 15px;">数学</a> <a href="/blog/tags/Redis/" style="font-size: 15px;">Redis</a> <a href="/blog/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/" style="font-size: 15px;">时间序列</a> <a href="/blog/tags/%E6%8A%95%E8%B5%84/" style="font-size: 15px;">投资</a> <a href="/blog/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/" style="font-size: 15px;">装饰器</a> <a href="/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/blog/tags/%E7%BB%9F%E8%AE%A1/" style="font-size: 15px;">统计</a> <a href="/blog/tags/%E6%A6%82%E7%8E%87/" style="font-size: 15px;">概率</a> <a href="/blog/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 15px;">贝叶斯</a> <a href="/blog/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/" style="font-size: 15px;">最小二乘法</a> <a href="/blog/tags/%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">矩阵</a> <a href="/blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">深度学习</a> <a href="/blog/tags/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/" style="font-size: 15px;">变分推断</a> <a href="/blog/tags/%E9%9A%8F%E6%9C%BA/" style="font-size: 15px;">随机</a> <a href="/blog/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" style="font-size: 15px;">信息论</a> <a href="/blog/tags/%E5%88%86%E5%B8%83/" style="font-size: 15px;">分布</a> <a href="/blog/tags/%E9%87%87%E6%A0%B7/" style="font-size: 15px;">采样</a> <a href="/blog/tags/%E5%85%89%E6%BB%91/" style="font-size: 15px;">光滑</a> <a href="/blog/tags/%E4%B8%8D%E7%AD%89%E5%BC%8F/" style="font-size: 15px;">不等式</a> <a href="/blog/tags/%E9%80%BC%E8%BF%91/" style="font-size: 15px;">逼近</a> <a href="/blog/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" style="font-size: 15px;">特征工程</a> <a href="/blog/tags/%E9%87%8F%E5%8C%96/" style="font-size: 15px;">量化</a> <a href="/blog/tags/%E8%AF%8D%E5%90%91%E9%87%8F/" style="font-size: 15px;">词向量</a> <a href="/blog/tags/%E4%BF%A1%E6%81%AF/" style="font-size: 15px;">信息</a> <a href="/blog/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">集成学习</a> <a href="/blog/tags/%E5%88%86%E7%B1%BB/" style="font-size: 15px;">分类</a> <a href="/blog/tags/%E8%AF%81%E6%98%8E/" style="font-size: 15px;">证明</a> <a href="/blog/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/blog/tags/%E5%9B%9E%E5%BD%92/" style="font-size: 15px;">回归</a> <a href="/blog/tags/%E6%8C%87%E6%A0%87/" style="font-size: 15px;">指标</a> <a href="/blog/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/" style="font-size: 15px;">交叉验证</a> <a href="/blog/tags/%E6%AD%A3%E5%88%99%E5%8C%96/" style="font-size: 15px;">正则化</a> <a href="/blog/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">神经网络</a> <a href="/blog/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/blog/tags/Embedding/" style="font-size: 15px;">Embedding</a> <a href="/blog/tags/Transformer/" style="font-size: 15px;">Transformer</a> <a href="/blog/tags/Attention/" style="font-size: 15px;">Attention</a> <a href="/blog/tags/%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">对抗训练</a> <a href="/blog/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/" style="font-size: 15px;">文本分类</a> <a href="/blog/tags/NER/" style="font-size: 15px;">NER</a> <a href="/blog/tags/%E6%A6%82%E7%8E%87%E5%9B%BE/" style="font-size: 15px;">概率图</a> <a href="/blog/tags/%E5%88%86%E8%AF%8D/" style="font-size: 15px;">分词</a> <a href="/blog/tags/%E5%B9%B6%E8%A1%8C/" style="font-size: 15px;">并行</a> <a href="/blog/tags/%E5%9B%BE/" style="font-size: 15px;">图</a> <a href="/blog/tags/HMM/" style="font-size: 15px;">HMM</a> <a href="/blog/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/" style="font-size: 15px;">可视化</a> <a href="/blog/tags/%E6%A2%AF%E5%BA%A6/" style="font-size: 15px;">梯度</a> <a href="/blog/tags/RNN/" style="font-size: 15px;">RNN</a> <a href="/blog/tags/LSTM/" style="font-size: 15px;">LSTM</a> <a href="/blog/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B/" style="font-size: 15px;">注意力</a> <a href="/blog/tags/%E5%BA%8F%E5%88%97%E7%BC%96%E7%A0%81/" style="font-size: 15px;">序列编码</a> <a href="/blog/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/blog/tags/%E5%8D%B7%E7%A7%AF/" style="font-size: 15px;">卷积</a> <a href="/blog/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" style="font-size: 15px;">注意力机制</a> <a href="/blog/tags/%E7%A3%81%E7%9B%98%E6%95%85%E9%9A%9C/" style="font-size: 15px;">磁盘故障</a> <a href="/blog/tags/%E4%BC%98%E5%8C%96/" style="font-size: 15px;">优化</a> <a href="/blog/tags/%E8%B0%83%E5%8F%82/" style="font-size: 15px;">调参</a> <a href="/blog/tags/BERT/" style="font-size: 15px;">BERT</a> <a href="/blog/tags/Flask/" style="font-size: 15px;">Flask</a> <a href="/blog/tags/web/" style="font-size: 15px;">web</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/blog/23811/">确定性变量的随机化技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/16228/">分析与拓展：Transformer中的MultiHeadAttention为什么使用scaled？</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/16113/">Tensorflow的多卡训练：原理和实践</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/16051/">机器学习之分类问题的评估指标总结</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/16003/">天马行空：设计自己的激活函数</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/15887/">函数光滑近似（4）：Heaviside step函数及其应用</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/15205/">引入参数控制softmax的smooth程度</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/15110/">分析与拓展：多分类模型的输出为什么使用softmax？</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/14990/">一种基于光滑逼近的正态分布采样法</a></li><li class="post-list-item"><a class="post-list-link" href="/blog/14721/">GELU由来：从狄拉克函数到GELU激活函数</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="github" target="_blank">github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2023 <a href="/blog/." rel="nofollow">Erwin Feng Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/blog/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/blog/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/blog/js/copycode.js?v=1.0.0" successtext="复制成功！"></script><link rel="stylesheet" type="text/css" href="/blog/css/copycode.css?v=1.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/blog/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/blog/js/smartresize.js?v=1.0.0"></script></div></body></html>